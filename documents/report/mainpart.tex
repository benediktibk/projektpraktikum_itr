
%_________Mainpart__________________________________

\chapter{System Identification}
\label{chap:system_identification}

The target of the system identification is to estimate the kinematics of the object, which are:
\begin{enumerate}
	\item mass $m$
	\item center of gravity, represented through the offset $\vec c$ from the grasping point to the center of gravity
	\item inertia matrix $\vec I_\scr{q}$, with respect to the center of gravity
\end{enumerate}

For simplicity we will first discuss the problem of the identification of the object kinematics with only one grasping point. Starting from these formulas, we will then continue with multiple grasping points, which is the case for cooperative identification.

\section{One Grasping Point}
\label{sec:one_grasping_point}

\begin{figure}
	\centering
	\include{tikz/load_one_grasping_point}
	\caption{Load with one grasping point}
	\label{fig:load_one_grasping_point}
\end{figure}

The system behaviour of a model like \ref{fig:load_one_grasping_point} can be described through 
\begin{equation}
	^\scr{L}\vec{F} = m {^\scr{W}}\vec{\ddot{p}} + m ^\scr{L}\vec{g} + ^\scr{L}\vec{\dot{\omega}} \times m ^\scr{L}\vec{c} + ^\scr{L}\vec{\omega} \times (^\scr{L}\vec{\omega} \times m ^\scr{L}\vec{c}),
	\label{eq:force}
\end{equation}
which is derived from the conservation of momentum, and
\begin{equation}
	^\scr{L}\vec{N} = ^\scr{L}\vec{I}_\scr{p} ^\scr{L}\vec{\dot{\omega}} + ^\scr{L}\vec{\omega} \times (^\scr{L}\vec{I}_\scr{p} ^\scr{L}\vec{\omega}) + m ^\scr{L}\vec{c} \times {^\scr{W}}\vec{\ddot{p}} + m ^\scr{L}\vec{c} \times ^\scr{L}\vec{g},
	\label{eq:torque}
\end{equation}
which comes from the conservation of angular momentum. Both formulas are taken from \ref{MISSING}, but are used here with a different definition of the gravity vector. Throughout this paper we assume that in the world coordinate frame $\vec g$ only has a component in the $z$-direction, with a negative value.

The inertia matrix $\vec I_\scr{p}$ in these formulas represents the inertia of the object transformed into the grasping point through the parallel axis theorem
\begin{equation}
	\vec I_\scr{p} = \vec I_\scr{q} + m \left( (\vec c^\scr{T} \vec c) \vec 1 - (\vec c \vec c^\scr{T}) \right).
\end{equation}
All values, besides the position of the object $\vec p$, are represented in the load frame, as for instance the angular velocity $\vec \omega$ of the endeffector. This value can be calculated as the derivative with respect to time of the orientation $^W\vec{\varphi}$ of the load coordinate frame in the world coordinate frame:
\begin{equation}
	{^\scr{W}}\vec{\omega} = \frac{\partial {^\scr{W}}\vec{\varphi}}{\partial t}
\end{equation}
For use in the estimator this value needs to be transformed into the load coordinate frame, which means that the rotation
\begin{equation}
	^\scr{L}\vec{\omega} = \vec{R}({^\scr{W}}\vec{\varphi}) {^\scr{W}}\vec{\omega}
\end{equation}
must be applied. For the graviation, which changes its direction in the load coordinate frame with the rotation of the object, the same rotation is necessary. For the sake of legibility we will not denote the coordinate frames anymore during the rest of this section.

In the case of only one grasping point we then have in total ten unknowns:
\begin{enumerate}
	\item mass $m$
	\item grasping point offset from the center of gravity $\vec c = [c_x, c_y, c_z]^\scr{T}$ with three unknowns
	\item inertia matrix with six unknowns, as this matrix is by definition symmetric
	\begin{equation}
		\vec{I}_\scr{p} = 
		\begin{bmatrix}	
			I_{xx}	& I_{xy}	& I_{xz} \\
			I_{xy}	& I_{yy}	& I_{yz} \\
			I_{xz}	& I_{yz}	& I_{zz}
		\end{bmatrix}
	\end{equation}
\end{enumerate}

These values are combined to the system parameter vector
\begin{equation}
	\vec{\Theta} = [m, m c_x, m c_y, m c_z, I_{xx}, I_{xy}, I_{xz}, I_{yy},I_{yz}, I_{zz}]^\scr{T},
\end{equation}
where in practice we do not know the correct values, but instead only the estimation $\vec{\hat \Theta}$.

For the estimator as input information we have a vector filled with the forces and torques at the grasping point
\begin{equation}
	\vec{h} = [F_x, F_y, F_z, M_x, M_y, M_z]^\scr{T},
\end{equation}
the position of the grasping point $\vec p$, the angular velocity $\vec \omega$ of the grasping point and the gravity $\vec g$. For a recursive least squares estimation we need now the linear relation
\begin{equation}
	\vec{h}(k) = \vec{\Phi}(k) \vec{\Theta}(k)
\end{equation}
between $\vec{\Theta}$ and $\vec{h}$ with
\begin{equation}
	\vec{\Phi}(k) = 
	\begin{bmatrix}
		\vec{\ddot p} - \vec{g}	& [\vec{\dot \omega} \times] + [\vec{\omega}\times] [\vec{\omega} \times]	& 0 \\
		0			& [(\vec{g} - \vec{\ddot p}) \times]									& [.  \vec{\dot \omega}] + [\vec{\omega} \times] [. \vec{\omega}]
	\end{bmatrix},
\end{equation}
which was derived in \ref{MISSING}.

The recursive least squares is then an iterative improvement of the estimation, where for every sampling step the formulas
\begin{equation}
	\vec{K}(k) = \vec{P}(k-1) \vec{\Phi}^\scr{T}(k) (\vec{I} + \vec{\Phi}(k) \vec{P}(k - 1) \vec{\Phi}^\scr{T}(k))^{-1}
\end{equation}
\begin{equation}
	\vec{P}(k) = (\vec{I} - \vec{K}(k) \vec{\Phi}(k)) \vec{P}(k - 1)
\end{equation}
\begin{equation}
	\vec{\hat \Theta}(k)=\vec{ \hat \Theta}(k - 1) + \vec{K}(k) (\vec{h}(k) - \vec{\Phi}(k) \vec{\hat \Theta}(k - 1))
\end{equation}
are applied \ref{MISSING}. The initialization of the algorithm can be done through
\begin{equation}
	\vec{P}(k_0) = \left( \vec{\Phi}^\scr{T}(k_0) \vec{\Phi}(k_0) \right)^{-1}
\end{equation}
and
\begin{equation}
	\vec{\hat \Theta} (k_0) = \vec{P}(k_0) \vec{\Phi}^\scr{T}(k_0) \vec{h}(k_0).
\end{equation}

\section{Multiple Grasping Points}
\label{sec:multiple_grasping_points}
\begin{figure}
	\centering
	\include{tikz/load_multiple_grasping_points}
	\caption{Load with multiple grasping points}
	\label{fig:load_multiple_grasping_points}
\end{figure}

Of course a load can also be hold by multiple manipulators, or arms in case of a human. As long as on every grasping point a force and torque sensor is mounted the basic principle of the previous section can be reused for the load estimation. In this case the forces and torques are distributed over all grippers, whereas the distribution depends on the reactive forces of the manipulators. Therefore, the only difference in the physics is that $n$ forces and torques are combined on the left hand sides of
\begin{equation}
	\sum_{i = 1}^{n}  {^\scr{L}}\vec{F}_{i} = m {^\scr{W}}\vec{\ddot{p}} + m {^\scr{L}}\vec{g} + {^\scr{L}}\vec{\dot{\omega}} \times m {^\scr{L}}\vec{c} + {^\scr{L}}\vec{\omega} \times ({^\scr{L}}\vec{\omega} \times m {^\scr{L}}\vec{c})
	\label{eq:force_multiple}	
\end{equation}
and
\begin{equation}
	\sum_{i = 1}^n {^\scr{L}}\vec{N}_{i} + \sum_{i = 2}^n {^\scr{L}}\vec{r}_{i} \times {^\scr{L}}\vec{F}_{i} = {^\scr{L}}\vec{I}_\scr{p} {^\scr{L}}\vec{\dot{\omega}} + {^\scr{L}}\vec{\omega} \times ({^\scr{L}}\vec{I}_\scr{p} {^\scr{L}}\vec{\omega}) + m {^\scr{L}}\vec{c} \times {^\scr{W}}\vec{\ddot{p}} + m {^\scr{L}}\vec{c} \times {^\scr{L}}\vec{g}.
	\label{eq:torque_multiple}	
\end{equation}
The additional summands for the torques are caused by the forces which are not applied in the grasping point one. Implicitly for these formulas we assume that the load coordinate system has its origin in the grasping point of gripper one and that the offsets ${^\scr{L}}\vec{r}_{i}$ from this gripper to the gripper $i$ are known. Additonally, we have again denoted the corresping coordinate systems, but we won't repeat this during the rest of the section for more legible formulas.

At this point nearly the same iterative steps can be applied to estimate the load kinematics. The difference lies here within the calculation of $\vec{h}$, which is in this case not only the combination of the forces and torques to a vector, but instead has to consider the total sums of forces, torques and torques caused by the forces. The total forces and torques can be taken from \ref{eq:force_multiple} and \ref{eq:torque_multiple}, which leads us to
\begin{equation}
	\vec{h} = 
	\begin{bmatrix}
		\sum_{i = 1}^n {^\scr{L}}\vec{F}_{i} \\
		\sum_{i = 1}^n {^\scr{L}}\vec{N}_{i} + \sum_{i = 2}^n {^\scr{L}}\vec{r}_{i} \times {^\scr{L}}\vec{F}_{i}
	\end{bmatrix}
\end{equation}

The rest of the recursive least squares is than the same as in \ref{chap:system_identification}.

\chapter{Simulation}
\label{chap:simulation}
For the purpose of a faster evaluation of our system identification algorithms we developed a simulation environment in \textsc{Matlab} Simulink. The model of the load object was implemented through \ref{eq:force} and \ref{eq:torque} in the case of one grasping point and through \ref{eq:force_multiple} and \ref{eq:torque_multiple} for multiple grasping points. In the second case we also had to distribute the forces and torques among the grasping points. In reality, this distribution is deterimed by the strength of the manipulators, but in the simulation it was sufficient to split the forces and torques up by an arbitrary choice. For a more realistic model we changed this distribution over time with sinusoidal functions. The excitation in terms of position and rotation was achieved through sinusoidal waves with different frequencies and phase shifts, which results in the necessary acceleration of the object.

As in reality the force and torques sensors typically have some noise on them we also ran our system identification algorithms on a model version, which had Gaussian white noise on the forces and torques. The deviation of the direct forces and the disturbed ones can be seen in \ref{fig:force_noisy}. Of course, the same noise level, but stochastically independent, was added to all forces and torques.

\begin{figure}
	\centering
	\includegraphics[scale=.7]{figures/force_noisy.eps}
	\caption{Force with Gaussian white noise}
	\label{fig:force_noisy}
\end{figure}

To test the system identification with one grasping point we simulated the identification of an object with $m = $\unit[2]{kg}, $c = \begin{bmatrix} \text{\unit[0.5]{m}} & \text{\unit[0.1]{m}} & \text{\unit[0.03]{m}} \end{bmatrix}^T$ and 
\begin{equation*}
	I = \begin{bmatrix} \text{\unit[0.0018]{$kg/m^2$}} & 0 & 0 \\ 0 & \text{\unit[0.0418]{$kg/m^2$}} & 0 \\ 0 & 0 & \text{\unit[0.0433]{$kg/m^2$}} \end{bmatrix}.
\end{equation*}

In the simulation the recursive least squares converges in this case within seconds, as it can be seen in \ref{fig:mass_error}, \ref{fig:grasping_offset_error} and \ref{fig:inertia_error}

\begin{figure}
	\centering
	\includegraphics[scale=.7]{figures/mass_error.eps}
	\caption{Error in mass estimation}
	\label{fig:mass_error}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=.7]{figures/grasping_offset_error.eps}
	\caption{Error in grasping offset estimation}
	\label{fig:grasping_offset_error}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=.7]{figures/inertia_error.eps}
	\caption{Error in inertia estimation}
	\label{fig:inertia_error}
\end{figure}

\chapter{Experimental Evaluation}
\label{chap:experimental_evaluation}

\section{Experimental Setup}
\subsection{Framework}
%% Florian
All experiments were carried out at the multi-robot lab located at the \textit{Chair of Information-Oriented Control} (TUM), which provides a variety of both robotic actuators and sensory equipment. The robotic part of our load estimation task is covered by a 7-DoF manipulator which can be controlled by either position, velocity or force commands. The manipulator's endeffector (EEF) is equipped with a \textsc{JR3} force-torque sensor and a \textsc{PG70} gripper. The forces and torques applied at the human agent's grasping points are measured using \textsc{JR3} force-torque sensors. Spatial information is gathered using a \textsc{Qualisys} motion-capture system, which tracks the position and orientation of a set of predefined rigid bodies in real-time. We track the robot base, the EEF as well as both grasping points of the human agent. The rigid body coordinate frames are aligned with the frame of the corresponding force-torque sensor.

!!! $\longrightarrow$ vibrotactile wrist bands !!!
\subsection{Data Acquisition}
%% Florian
The \textsc{JR3} force-torque sensors provide data at a resolution of up to \unit[8]{kHz}. The real-time output of the \textsc{Qualisys} motion-capture system runs at a sampling rate of \unit[150]{Hz}. Information on the current endeffector pose gathered by joint encoders is provided at a sampling rate of \unit[1]{kHz}. All data mentioned above is streamed into a single \textsc{Matlab} Simulink model, executed on a real-time \textsc{Linux} operating system. Furthermore the Simulink model processes the data and forwards actuator commands to the relevant robot manipulator.

!!! $\longrightarrow$ vibrotactile wrist bands !!!

\subsection{Data Processing}
%% Florian
The estimation task derived in Section \ref{sec:multiple_grasping_points} requires information on the EEF position, acceleration, angular velocity and angular acceleration. Furthermore all forces and torques acting at the grasping points have to be expressed with respect to the EEF coordinate frame before being fed into the estimator and thus require an euclidean transform from the force-torque sensor measurement frame.

Initial tests with all data being processed at \unit[1]{kHz}, led to a number of issues. As a consequence of its significantly lower sampling-rate, the processing model has to hold each value received from the motion-capture system for number of samples.  The consecutive identical samples again result in very error prone first
and second derivatives.

Due to the nature of our estimation task it is however sufficient to acquire and process all data at a reduced sampling-rate of \unit[100]{Hz}, avoiding consecutive values in position and orientation data. In addition to the lower sampling-rate, all signals are filtered with a Butterworth low-pass (Order: 3, $\omega_\scr{c} = $\unit[30]{Hz}). The introduced phase-lag has no effect on the estimation task, as all signals experience the identical delay.

!!! $\longrightarrow$ vibrotactile wrist bands !!!

\section{Results}
\subsection{Load Identification: Robot}
\subsection{Load Identification: Human-Robot Cooperation}
